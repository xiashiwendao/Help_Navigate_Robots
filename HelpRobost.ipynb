{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"D:\\\\practicespace\\\\github\\\\Help_Navigate_Robots\\\\dataset\")\n",
    "dataset_x = []\n",
    "i = 0\n",
    "data_count = 1000\n",
    "datalist=[]\n",
    "\n",
    "data_x = pd.read_csv(\"x_train.csv\", nrows=data_count, usecols=[1,2,3,4,5,6,7,8,9,9,10,11,12])\n",
    "#print(data_x.describe())\n",
    "#print(data_x.head())\n",
    "#print(data_x.shape)\n",
    "\n",
    "data_y = pd.read_csv(\"y_train.csv\", nrows=data_count, usecols=[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "耗时： 4.045496627147454\n"
     ]
    }
   ],
   "source": [
    "from numpy import shape\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "datas = [line.split(\",\") for line in open(\"x_train.csv\")]\n",
    "dataArr = array(datas)\n",
    "shape(dataArr)\n",
    "end = timeit.default_timer()\n",
    "cost_time = end - start\n",
    "print(\"耗时：\", cost_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "\n",
    "def loadDataSet(filePath, startRow=0, rowTotalCount=inf):\n",
    "    dataList = []\n",
    "    index = 0\n",
    "    endRow = startRow + rowTotalCount -1\n",
    "    for line in open(filePath):\n",
    "        if(index<startRow):\n",
    "            continue\n",
    "        if(index>endRow):\n",
    "            break;\n",
    "        sample = line.split(\",\")\n",
    "        dataList.append(sample)\n",
    "        index+=1\n",
    "    return dataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>orientation_X</th>\n",
       "      <th>orientation_Y</th>\n",
       "      <th>orientation_Z</th>\n",
       "      <th>orientation_W</th>\n",
       "      <th>angular_velocity_Y</th>\n",
       "      <th>angular_velocity_Z</th>\n",
       "      <th>linear_acceleration_Y</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935_63</td>\n",
       "      <td>-0.65046</td>\n",
       "      <td>0.74478</td>\n",
       "      <td>0.107580</td>\n",
       "      <td>-0.10315</td>\n",
       "      <td>0.13747</td>\n",
       "      <td>-0.50052</td>\n",
       "      <td>3.8650</td>\n",
       "      <td>7</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149_27</td>\n",
       "      <td>-0.96369</td>\n",
       "      <td>0.22115</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>-0.14780</td>\n",
       "      <td>0.20416</td>\n",
       "      <td>-0.44864</td>\n",
       "      <td>-7.3334</td>\n",
       "      <td>7</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149_26</td>\n",
       "      <td>-0.96350</td>\n",
       "      <td>0.22172</td>\n",
       "      <td>0.023839</td>\n",
       "      <td>-0.14810</td>\n",
       "      <td>0.08284</td>\n",
       "      <td>-0.49656</td>\n",
       "      <td>-6.3048</td>\n",
       "      <td>7</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           row_id  orientation_X  orientation_Y  orientation_Z  orientation_W  \\\n",
       "series_id                                                                       \n",
       "935        935_63       -0.65046        0.74478       0.107580       -0.10315   \n",
       "149        149_27       -0.96369        0.22115       0.023597       -0.14780   \n",
       "149        149_26       -0.96350        0.22172       0.023839       -0.14810   \n",
       "\n",
       "           angular_velocity_Y  angular_velocity_Z  linear_acceleration_Y  \\\n",
       "series_id                                                                  \n",
       "935                   0.13747            -0.50052                 3.8650   \n",
       "149                   0.20416            -0.44864                -7.3334   \n",
       "149                   0.08284            -0.49656                -6.3048   \n",
       "\n",
       "           group_id surface  \n",
       "series_id                    \n",
       "935               7  carpet  \n",
       "149               7  carpet  \n",
       "149               7  carpet  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "pd_x = pd.read_csv(\"x_train.csv\")\n",
    "end_time = time.time()\n",
    "#print(\"pandas阅读csv文件耗时: \", end_time - start_time)\n",
    "pd_y = pd.read_csv(\"y_train.csv\")\n",
    "pd_data = pd_x.set_index(\"series_id\").join(pd_y.set_index(\"series_id\"))\n",
    "# 判断一下相关性，对于相关性低的列进行删除\n",
    "corr_matrix = pd_sorted_data.corr()\n",
    "corr_matrix[\"group_id\"].sort_values(ascending=True)\n",
    "pd_data.drop(columns=[\"linear_acceleration_Z\",\"angular_velocity_X\",\"linear_acceleration_X\",\"measurement_number\"], inplace=True)\n",
    "\n",
    "pd_sorted_data = pd_data.sort_values(by=\"surface\")\n",
    "pd_sorted_data.head(3)\n",
    "\n",
    "sample_train = pd_sorted_data.values[:, 1:]\n",
    "pd_sorted_data.head(3)\n",
    "#print(sample_train[:, :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sample count:  487680\n",
      "column of sample:  9\n",
      "{'carpet': 24192, 'hard_tiles_large_space': 39424, 'tiled': 65792, 'soft_pvc': 93696, 'hard_tiles': 2688, 'fine_concrete': 46464, 'wood': 77696, 'concrete': 99712, 'soft_tiles': 38016}\n",
      "{'carpet': 15966, 'hard_tiles_large_space': 26019, 'concrete': 65809, 'soft_pvc': 61839, 'hard_tiles': 1774, 'tiled': 43422, 'wood': 51279, 'fine_concrete': 30666, 'soft_tiles': 25090}\n",
      "trainDataCount:  321864\n"
     ]
    }
   ],
   "source": [
    "# 获取各种分类的数量\n",
    "classCount = {}\n",
    "for sample in sample_train:\n",
    "    #print(sample)\n",
    "    y = sample[-1]\n",
    "    data_y.append(y)\n",
    "    \n",
    "    if target == \"\" or y != target:\n",
    "        target = y\n",
    "        seria_count = 0\n",
    "    seria_count += 1\n",
    "    classCount[target] = classCount.get(target, 0) + 1\n",
    "\n",
    "# 根据2/3数据用于训练，1/3数据用于验证的原则进行测试样本数据分配\n",
    "classTrainCount={}\n",
    "trainDataCount = 0\n",
    "for key in classCount.keys():\n",
    "    trainCount = int(classCount[key] * 0.66)\n",
    "    classTrainCount[key] = trainCount\n",
    "    trainDataCount += trainCount\n",
    "\n",
    "print(\"total sample count: \", len(sample_train))\n",
    "print(\"column of sample: \", len(sample_train[0]))\n",
    "print(classCount)\n",
    "print(classTrainCount)\n",
    "print(\"trainDataCount: \", trainDataCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_x_train_array shape:  (321864, 8)\n",
      "data_y_train_array shape:  (321864,)\n",
      "data_x_validate_array shape:  (165816, 8)\n",
      "data_y_validate_array shape:  (165816,)\n"
     ]
    }
   ],
   "source": [
    "data_x = []\n",
    "data_y = []\n",
    "data_x_train = []\n",
    "data_y_train = []\n",
    "data_x_validate = []\n",
    "data_y_validate = []\n",
    "\n",
    "target = \"\"\n",
    "seria_count = 0\n",
    "\n",
    "# 获取训练集（train set）以及验证集（validate set）\n",
    "for sample in sample_train:\n",
    "    x = sample[:-1]\n",
    "    data_x.append(x)\n",
    "    y = sample[-1]\n",
    "    data_y.append(y)\n",
    "    \n",
    "    if y != target:\n",
    "        target = y\n",
    "        seria_count = 0\n",
    "    seria_count += 1\n",
    "    validate_sample_count = classTrainCount.get(target)\n",
    "    #print(\"target: %s, validate_sample_count: %d\" % (target, validate_sample_count))\n",
    "    if(seria_count <= validate_sample_count):\n",
    "        #print(\"seria_count: %d, validate_sample_count: %d，还是在训练集集范围内\" % (seria_count, validate_sample_count))\n",
    "        data_x_train.append(x)\n",
    "        data_y_train.append(y)\n",
    "    else:\n",
    "        #print(\"seria_count: %d, validate_sample_count: %d，在验证集集范围内\" % (seria_count, validate_sample_count))\n",
    "        data_x_validate.append(x)\n",
    "        data_y_validate.append(y)\n",
    "\n",
    "data_x_train_array = array(data_x_train)\n",
    "data_y_train_array = array(data_y_train)\n",
    "data_x_validate_array = array(data_x_validate)\n",
    "data_y_validate_array = array(data_y_validate)\n",
    "\n",
    "print(\"data_x_train_array shape: \", shape(data_x_train_array))\n",
    "print(\"data_y_train_array shape: \", shape(data_y_train_array))\n",
    "print(\"data_x_validate_array shape: \", shape(data_x_validate_array))\n",
    "print(\"data_y_validate_array shape: \", shape(data_y_validate_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count: 1975, ok_count: 163841, error_rate: 0.011911\n"
     ]
    }
   ],
   "source": [
    "#决策树模型，发现当max_depth=20的时候，错误率下降到了1.1%~1.2%；\n",
    "# max_depth=40的时候，错误率1%；\n",
    "# => 20已经是最佳深度\n",
    "\n",
    "#data_y.head()\n",
    "tree = DecisionTreeClassifier(max_depth=20)\n",
    "tree.fit(data_x_train_array, data_y_train_array)\n",
    "data_y_predict_array = tree.predict(data_x_validate_array)\n",
    "\n",
    "# 验证模型\n",
    "predict_count = len(data_y_predict_array)\n",
    "#print(len(data_y_predict_array))\n",
    "#print(len(data_y_validate_array))\n",
    "\n",
    "caculateErrorRate(predict_count, data_y_predict_array, data_y_validate_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculateErrorRate(predict_count, data_y_predict_array, data_y_validate_array):\n",
    "    error_count = 0\n",
    "    ok_count = 0\n",
    "    for i in range(predict_count):\n",
    "        if(data_y_predict_array[i] != data_y_validate_array[i]):\n",
    "            error_count += 1\n",
    "        else:\n",
    "            ok_count += 1\n",
    "\n",
    "    print(\"error_count: %d, ok_count: %d, error_rate: %f\" % (error_count, ok_count, error_count/ predict_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count: 19, ok_count: 165797, error_rate: 0.000115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KNN发现neighbor设置为1，反而错误率更低（6.4%），默认是5错误率是7%，设置10个错误率8.4%,20则为10%，近邻越高你会发现准确率越低\n",
    "# 后来把相关性差的几列删除掉之后，惊讶的发现竟然下降到了0.01%，是的error rate是：0.000115\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(data_x_train_array, data_y_train_array)\n",
    "data_y_predict_array = knn.predict(data_x_validate_array)\n",
    "# 验证模型\n",
    "predict_count = len(data_y_predict_array)\n",
    "\n",
    "caculateErrorRate(predict_count, data_y_predict_array, data_y_validate_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count: 59733, ok_count: 106083, error_rate: 0.360237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "forest.fit(data_x_train_array, data_y_train_array)\n",
    "data_y_predict_array = forest.predict(data_x_validate_array)\n",
    "# 验证模型\n",
    "predict_count = len(data_y_predict_array)\n",
    "\n",
    "caculateErrorRate(predict_count, data_y_predict_array, data_y_validate_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error_count: 1420, ok_count: 164396, error_rate: 0.008564\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "voteCls = VotingClassifier(estimators=[(\"dt\", tree), (\"knn\", knn),(\"forest\", forest)], voting=\"hard\")\n",
    "voteCls.fit(data_x_train_array, data_y_train_array)\n",
    "data_y_predict_array = voteCls.predict(data_x_validate_array)\n",
    "\n",
    "predict_count = len(data_y_predict_array)\n",
    "caculateErrorRate(predict_count, data_y_predict_array, data_y_validate_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
