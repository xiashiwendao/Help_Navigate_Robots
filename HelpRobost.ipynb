{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import zeros\n",
    "os.chdir(\"D:\\\\practicespace\\\\github\\\\Help_Navigate_Robots\\\\dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据进行join操作，然后按照分类进行排序（用于后面统计各个分类数量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.65046, 0.74478, 0.10758, ..., 0.4686493184634448, 7, 'carpet'],\n",
       "       [-0.9636899999999999, 0.22115, 0.023597, ..., 0.4573623650203576,\n",
       "        7, 'carpet'],\n",
       "       [-0.9635, 0.22171999999999997, 0.023839, ..., 0.45401309966365727,\n",
       "        7, 'carpet'],\n",
       "       ...,\n",
       "       [0.67332, -0.72425, -0.10549000000000001, ...,\n",
       "        0.49297008320056646, 38, 'wood'],\n",
       "       [0.67156, -0.72587, -0.10582000000000001, ..., 0.4647980173482032,\n",
       "        38, 'wood'],\n",
       "       [-0.089847, -0.98464, -0.14944000000000002, ...,\n",
       "        0.4669647725261108, 43, 'wood']], dtype=object)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getSampleData():\n",
    "    # 读入数据，加载到Pandas里面\n",
    "    start_time = time.time()\n",
    "    pd_x = pd.read_csv(\"x_train.csv\")\n",
    "    end_time = time.time()\n",
    "    #print(\"pandas阅读csv文件耗时: \", end_time - start_time)\n",
    "    pd_y = pd.read_csv(\"y_train.csv\")\n",
    "    pd_data = pd_x.set_index(\"series_id\").join(pd_y.set_index(\"series_id\"))\n",
    "    \n",
    "    # 对数据列进行归一化\n",
    "    max_min_scalar = lambda x: (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "    normed_Z = pd_data[[\"linear_acceleration_Z\"]].apply(max_min_scalar) # 注意这里一定是套了两层中括号\n",
    "    normed_Y = pd_data[[\"linear_acceleration_Y\"]].apply(max_min_scalar)\n",
    "    pd_data[\"linear_acceleration_Z\"] = normed_Z\n",
    "    pd_data[\"linear_acceleration_Y\"] = normed_Y\n",
    "    \n",
    "#     # 下面对于相关性进行计算，删掉相关性小的字段\n",
    "#     pd_data.drop(\"linear_acceleration_X\", axis=1, inplace=True)\n",
    "#     pd_data.drop(\"angular_velocity_X\", axis=1, inplace=True)\n",
    "#     pd_data.drop(\"linear_acceleration_Z\", axis=1, inplace=True)    \n",
    "#     print(\"删除相关性低的列之后...\")\n",
    "#     print(pd_data.head(3))\n",
    "    \n",
    "    pd_data_sorted = pd_data.sort_values(by=[\"surface\"])\n",
    "    sample_train = pd_data_sorted.values[:, 2:]\n",
    "    #print(sample_train[:3, :])\n",
    "    totalCount = shape(sample_train)[0]\n",
    "    print(\"样本总数为: %s, 0.6分割点: %s\" % (totalCount, int(totalCount * 0.6)))\n",
    "    \n",
    "    return sample_train\n",
    "\n",
    "getSampleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 读入数据，加载到Pandas里面\n",
    "# start_time = time.time()\n",
    "# pd_x = pd.read_csv(\"x_train.csv\")\n",
    "# end_time = time.time()\n",
    "# #print(\"pandas阅读csv文件耗时: \", end_time - start_time)\n",
    "# pd_y = pd.read_csv(\"y_train.csv\")\n",
    "# pd_data = pd_x.set_index(\"series_id\").join(pd_y.set_index(\"series_id\"))\n",
    "# print(pd_data.head(3))\n",
    "# # 分析一下相关性，但是发现除了“measurement_number，linear_acceleration_X，angular_velocity_X，linear_acceleration_Z”\n",
    "# # 无关之外其他字段还好\n",
    "# corr_mastrix = pd_data.corr()\n",
    "# corr_mastrix\n",
    "# corr_mastrix[\"group_id\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'carpet': 24192,\n",
       " 'concrete': 99712,\n",
       " 'fine_concrete': 46464,\n",
       " 'hard_tiles': 2688,\n",
       " 'hard_tiles_large_space': 39424,\n",
       " 'soft_pvc': 93696,\n",
       " 'soft_tiles': 38016,\n",
       " 'tiled': 65792,\n",
       " 'wood': 77696}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计各个分类的数量，用于后续划分测试集合和验证集合\n",
    "def getClassCount(sample_train):\n",
    "    classCount = {}\n",
    "\n",
    "    for sample in sample_train:\n",
    "        className = sample[-1]\n",
    "        classCount[className] = classCount.get(className, 0) + 1\n",
    "\n",
    "    return classCount\n",
    "\n",
    "sample_train = getSampleData()\n",
    "getClassCount(sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n",
      "data_x_train_array shape:  (292604, 11)\n",
      "data_y_train_array shape:  (292604,)\n",
      "data_x_validate_array shape:  (195076, 11)\n",
      "data_y_validate_array shape:  (195076,)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "def splitTrainAndValidateData(sample_train, classCount):\n",
    "    # 获取训练集合以及验证集合\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_x_train = []\n",
    "    data_y_train = []\n",
    "    data_x_validate = []\n",
    "    data_y_validate = []\n",
    "\n",
    "    target = \"\"\n",
    "    seria_count = 0\n",
    "    validate_sample_count = 100\n",
    "\n",
    "    for sample in sample_train:\n",
    "        #print(sample)\n",
    "        x = sample[:-1]\n",
    "        data_x.append(x)\n",
    "        y = sample[-1]\n",
    "        data_y.append(y)\n",
    "\n",
    "        if y != target:\n",
    "            target = y\n",
    "            seria_count = 0\n",
    "            validate_sample_count = int(classCount[target]*0.6)\n",
    "            #print(\"class: [%s] validate count: %d \" % ( target, validate_sample_count))\n",
    "        seria_count += 1\n",
    "        if(seria_count <= validate_sample_count):\n",
    "            #print(\"target is: %s, seria_count is: %s, branch: train\" % (target, seria_count))\n",
    "            data_x_train.append(x)\n",
    "            data_y_train.append(y)\n",
    "        else:\n",
    "            #print(\"target is: %s, seria_count is: %s, branch: validate\" % (target, seria_count))\n",
    "            data_x_validate.append(x)\n",
    "            data_y_validate.append(y)\n",
    "\n",
    "    data_x_train_array = array(data_x_train)\n",
    "    data_y_train_array = array(data_y_train)\n",
    "    data_x_validate_array = array(data_x_validate)\n",
    "    data_y_validate_array = array(data_y_validate)\n",
    "\n",
    "    print(\"data_x_train_array shape: \", shape(data_x_train_array))\n",
    "    print(\"data_y_train_array shape: \", shape(data_y_train_array))\n",
    "    print(\"data_x_validate_array shape: \", shape(data_x_validate_array))\n",
    "    print(\"data_y_validate_array shape: \", shape(data_y_validate_array))\n",
    "    \n",
    "    return data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array\n",
    "\n",
    "sample_train = getSampleData()\n",
    "classCount = getClassCount(sample_train)\n",
    "data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array = splitTrainAndValidateData(sample_train, classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndValidate(ctl, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array):\n",
    "    # 训练\n",
    "    ctl.fit(data_x_train_array, data_y_train_array)\n",
    "    # 预测\n",
    "    y_predict = ctl.predict(data_x_validate_array)\n",
    "    size = len(y_predict)\n",
    "    # 统计错误率\n",
    "    ok_count = 0\n",
    "    error_count  = 0\n",
    "    for index in range(size):\n",
    "        if y_predict[index] == data_y_validate_array[index]:\n",
    "            ok_count +=1\n",
    "        else:\n",
    "            error_count += 1\n",
    "    # 输出结果\n",
    "    print(\"数据总量%d，错误数：%d，错误率：%f\" %(size, error_count, error_count/size))\n",
    "    scores = cross_val_score(knn, data_x_train_array, data_y_train_array, cv=5, scoring=\"accuracy\")\n",
    "    print(\"cross_val_score: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n",
      "data_x_train_array shape:  (292604, 11)\n",
      "data_y_train_array shape:  (292604,)\n",
      "data_x_validate_array shape:  (195076, 11)\n",
      "data_y_validate_array shape:  (195076,)\n"
     ]
    }
   ],
   "source": [
    "# 获取训练数据集\n",
    "def getData():\n",
    "    sample_train = getSampleData()\n",
    "    classCount = getClassCount(sample_train)\n",
    "    return splitTrainAndValidateData(sample_train, classCount)\n",
    "\n",
    "data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array = getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：80，错误率：0.000410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97432795, 0.99888244, 0.99947709])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "fitAndValidate(knn, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(knn, data_x_train_array, data_y_train_array, cv=3, scoring=\"accuracy\")\n",
    "# 未降维之前\n",
    "# 数据总量195076，错误数：13042，错误率：0.066856\n",
    "\n",
    "# 去掉了measurement_number列之后，\n",
    "# 数据总量195076，错误数：1238，错误率：0.006346\n",
    "\n",
    "# 对于“linear_acceleration_Y”和“linear_acceleration_Z”归一化之后\n",
    "# 数据总量195076，错误数：80，错误率：0.000410\n",
    "\n",
    "# 降维后（删掉了不相关的列之后）\n",
    "# 数据总量195076，错误数：0，错误率：0.000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：1928，错误率：0.009883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99690725, 0.99974369, 0.99948735, 0.99931646, 0.99947024])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=12, random_state=42)\n",
    "fitAndValidate(tree, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "\n",
    "cross_val_score(knn, data_x_train_array, data_y_train_array, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "# 未降维之前\n",
    "# 数据总量195076，错误数：2527，错误率：0.012954\n",
    "\n",
    "# 去掉了measurement_number列之后，\n",
    "# 数据总量195076，错误数：1928，错误率：0.009883\n",
    "\n",
    "# 对于“linear_acceleration_Y”和“linear_acceleration_Z”归一化之后\n",
    "# 数据总量195076，错误数：1928，错误率：0.009883\n",
    "\n",
    "# 降维后（删掉了不相关的列之后）\n",
    "# 数据总量195076，错误数：2768，错误率：0.014189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：1928，错误率：0.009883\n",
      "cross_val_score:  [0.99690725 0.99974369 0.99948735 0.99931646 0.99947024]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=300,max_depth=15, max_leaf_nodes=15, n_jobs=-1)\n",
    "fitAndValidate(tree, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "# 未降维前\n",
    "# 数据总量195076，错误数：2620，错误率：0.013431\n",
    "\n",
    "# 去掉了measurement_number列之后，\n",
    "# 数据总量195076，错误数：1928，错误率：0.009883\n",
    "\n",
    "# 对于“linear_acceleration_Y”和“linear_acceleration_Z”归一化之后\n",
    "# 数据总量195076，错误数：1928，错误率：0.009883\n",
    "\n",
    "# 降维后（删掉了不相关的列之后）\n",
    "# 数据总量195076，错误数：2768，错误率：0.014189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:144: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：148914，错误率：0.763364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "fitAndValidate(sgd, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "# 错误率70%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "### knn对于归一化还是比较敏感，但是下面的tree和randomForest则发现对于归一化没有反应；但是大部分的算法对于measurement_number这一列去掉之后的反应还是很明显的，这一列就是一个自增长，和分类毫无关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
