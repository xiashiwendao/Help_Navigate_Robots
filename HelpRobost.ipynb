{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"D:\\\\practicespace\\\\github\\\\Help_Navigate_Robots\\\\dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将数据进行join操作，然后按照分类进行排序（用于后面统计各个分类数量）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[63, -0.65046, 0.74478, ..., -9.201, 7, 'carpet'],\n",
       "       [27, -0.9636899999999999, 0.22115, ..., -10.795, 7, 'carpet'],\n",
       "       [26, -0.9635, 0.22171999999999997, ..., -11.267999999999999, 7,\n",
       "        'carpet'],\n",
       "       ...,\n",
       "       [35, 0.67332, -0.72425, ..., -5.7663, 38, 'wood'],\n",
       "       [46, 0.67156, -0.72587, ..., -9.7449, 38, 'wood'],\n",
       "       [0, -0.089847, -0.98464, ..., -9.4389, 43, 'wood']], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "def getSampleData():\n",
    "    # 读入数据，加载到Pandas里面\n",
    "    start_time = time.time()\n",
    "    pd_x = pd.read_csv(\"x_train.csv\")\n",
    "    end_time = time.time()\n",
    "    #print(\"pandas阅读csv文件耗时: \", end_time - start_time)\n",
    "    pd_y = pd.read_csv(\"y_train.csv\")\n",
    "    pd_data = pd_x.set_index(\"series_id\").join(pd_y.set_index(\"series_id\"))\n",
    "    #print(pd_data.head(3))\n",
    "    pd_data_sorted = pd_data.sort_values(by=[\"surface\"])\n",
    "    sample_train = pd_data_sorted.values[:, 1:]\n",
    "    #print(sample_train[:3, :])\n",
    "    totalCount = shape(sample_train)[0]\n",
    "    print(\"样本总数为: %s, 0.6分割点: %s\" % (totalCount, int(totalCount * 0.6)))\n",
    "    \n",
    "    return sample_train\n",
    "\n",
    "getSampleData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'carpet': 24192,\n",
       " 'concrete': 99712,\n",
       " 'fine_concrete': 46464,\n",
       " 'hard_tiles': 2688,\n",
       " 'hard_tiles_large_space': 39424,\n",
       " 'soft_pvc': 93696,\n",
       " 'soft_tiles': 38016,\n",
       " 'tiled': 65792,\n",
       " 'wood': 77696}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 统计各个分类的数量，用于后续划分测试集合和验证集合\n",
    "def getClassCount(sample_train):\n",
    "    classCount = {}\n",
    "\n",
    "    for sample in sample_train:\n",
    "        className = sample[-1]\n",
    "        classCount[className] = classCount.get(className, 0) + 1\n",
    "\n",
    "    return classCount\n",
    "\n",
    "sample_train = getSampleData()\n",
    "getClassCount(sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalData(dataset):\n",
    "    datasize = len(dataset)\n",
    "    minDatas = dataset.min(axis=0)\n",
    "    maxDatas = dataset.max(axis=0)\n",
    "    rangeDiff = maxDatas - minDatas\n",
    "    sqDiffValue = (dataset - tile(minDatas, (datasize, 1)))**2\n",
    "    sqDiffValueSum = \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n",
      "data_x_train_array shape:  (292604, 12)\n",
      "data_y_train_array shape:  (292604,)\n",
      "data_x_validate_array shape:  (195076, 12)\n",
      "data_y_validate_array shape:  (195076,)\n"
     ]
    }
   ],
   "source": [
    "def splitTrainAndValidateData(sample_train, classCount):\n",
    "    # 获取训练集合以及验证集合\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    data_x_train = []\n",
    "    data_y_train = []\n",
    "    data_x_validate = []\n",
    "    data_y_validate = []\n",
    "\n",
    "    target = \"\"\n",
    "    seria_count = 0\n",
    "    validate_sample_count = 100\n",
    "\n",
    "    for sample in sample_train:\n",
    "        #print(sample)\n",
    "        x = sample[:-1]\n",
    "        data_x.append(x)\n",
    "        y = sample[-1]\n",
    "        data_y.append(y)\n",
    "\n",
    "        if y != target:\n",
    "            target = y\n",
    "            seria_count = 0\n",
    "            validate_sample_count = int(classCount[target]*0.6)\n",
    "            #print(\"class: [%s] validate count: %d \" % ( target, validate_sample_count))\n",
    "        seria_count += 1\n",
    "        if(seria_count <= validate_sample_count):\n",
    "            #print(\"target is: %s, seria_count is: %s, branch: train\" % (target, seria_count))\n",
    "            data_x_train.append(x)\n",
    "            data_y_train.append(y)\n",
    "        else:\n",
    "            #print(\"target is: %s, seria_count is: %s, branch: validate\" % (target, seria_count))\n",
    "            data_x_validate.append(x)\n",
    "            data_y_validate.append(y)\n",
    "\n",
    "    data_x_train_array = array(data_x_train)\n",
    "    data_y_train_array = array(data_y_train)\n",
    "    data_x_validate_array = array(data_x_validate)\n",
    "    data_y_validate_array = array(data_y_validate)\n",
    "\n",
    "    print(\"data_x_train_array shape: \", shape(data_x_train_array))\n",
    "    print(\"data_y_train_array shape: \", shape(data_y_train_array))\n",
    "    print(\"data_x_validate_array shape: \", shape(data_x_validate_array))\n",
    "    print(\"data_y_validate_array shape: \", shape(data_y_validate_array))\n",
    "    \n",
    "    return data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array\n",
    "\n",
    "sample_train = getSampleData()\n",
    "classCount = getClassCount(sample_train)\n",
    "data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array = splitTrainAndValidateData(sample_train, classCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitAndValidate(ctl, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array):\n",
    "    # 训练\n",
    "    ctl.fit(data_x_train_array, data_y_train_array)\n",
    "    # 预测\n",
    "    y_predict = ctl.predict(data_x_validate_array)\n",
    "    size = len(y_predict)\n",
    "    # 统计错误率\n",
    "    ok_count = 0\n",
    "    error_count  = 0\n",
    "    for index in range(size):\n",
    "        if y_predict[index] == data_y_validate_array[index]:\n",
    "            ok_count +=1\n",
    "        else:\n",
    "            error_count += 1\n",
    "    # 输出结果\n",
    "    print(\"数据总量%d，错误数：%d，错误率：%f\" %(size, error_count, error_count/size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总数为: 487680, 0.6分割点: 292608\n",
      "data_x_train_array shape:  (292604, 12)\n",
      "data_y_train_array shape:  (292604,)\n",
      "data_x_validate_array shape:  (195076, 12)\n",
      "data_y_validate_array shape:  (195076,)\n"
     ]
    }
   ],
   "source": [
    "# 获取训练数据集\n",
    "def getData():\n",
    "    sample_train = getSampleData()\n",
    "    classCount = getClassCount(sample_train)\n",
    "    return splitTrainAndValidateData(sample_train, classCount)\n",
    "\n",
    "data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array = getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：13042，准确率：0.066856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "fitAndValidate(knn, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "\n",
    "# 未降维之前\n",
    "# 数据总量195076，错误数：13042，错误率：0.066856"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：2559，准确率：0.013118\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=12, random_state=42)\n",
    "fitAndValidate(tree, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "# 未降维之前\n",
    "# 数据总量195076，错误数：2527，错误率：0.012954"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据总量195076，错误数：2416，准确率：0.012385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier(n_estimators=300,max_depth=15, max_leaf_nodes=15, n_jobs=-1)\n",
    "fitAndValidate(tree, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "# 未降维前\n",
    "# 数据总量195076，错误数：2620，错误率：0.013431"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-f51128dc97ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfitAndValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x_train_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y_train_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x_validate_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y_validate_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-c15129ffff44>\u001b[0m in \u001b[0;36mfitAndValidate\u001b[1;34m(ctl, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfitAndValidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x_train_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y_train_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_x_validate_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y_validate_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x_train_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y_train_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x_validate_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                          sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self._max_iter,\n\u001b[1;32m--> 572\u001b[1;33m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         if (self._tol is not None and self._tol > -np.inf\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                  \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m                                  \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m                                  max_iter=max_iter)\n\u001b[0m\u001b[0;32m    527\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             self._fit_binary(X, y, alpha=alpha, C=C,\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_multiclass\u001b[1;34m(self, X, y, alpha, C, learning_rate, sample_weight, max_iter)\u001b[0m\n\u001b[0;32m    619\u001b[0m                                 \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m                                 1., sample_weight)\n\u001b[1;32m--> 621\u001b[1;33m             for i in range(len(self.classes_)))\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;31m# take the maximum of n_iter_ over every binary fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    823\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 825\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    826\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 261\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\software\\develop\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight)\u001b[0m\n\u001b[0;32m    419\u001b[0m                            \u001b[0mpos_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m                            \u001b[0mlearning_rate_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meta0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m                            est.power_t, est.t_, intercept_decay)\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "fitAndValidate(sgd, data_x_train_array, data_y_train_array, data_x_validate_array, data_y_validate_array)\n",
    "# 错误率70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
